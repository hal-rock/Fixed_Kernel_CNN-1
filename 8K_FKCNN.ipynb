{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from skimage import img_as_float\n",
    "from torch import nn, FloatTensor\n",
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "import sys\n",
    "import copy\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#link to thesis-yimeng-v2 directory for data\n",
    "sys.path.append(\"/home/ziniuw/thesis-yimeng-v2\")\n",
    "from thesis_v2.data.prepared.yuanyuan_8k import get_data\n",
    "from util.get_data_NS import reorginize_data\n",
    "from models_8K.model import FKCNN_2l, FKCNN_3l\n",
    "data = get_data('a', 256, 128, ['042318'], read_only=False, scale=0.5)\n",
    "data_Sep = reorginize_data(data) #train model one at a time\n",
    "weight = np.load(\"/home/ziniuw/Tangdata/filter_79.npy\")\n",
    "gabor = np.load(\"/home/ziniuw/Tangdata/gabor.npy\")\n",
    "gabor = gabor.reshape(24,1,10,10)\n",
    "weight = weight.reshape(79,1,9,9)\n",
    "weight = weight[[0,3,5,8,9,11,14,17,18,20,23,25,27,32,36,37,40,44,53,57,58,64,65,74],:,:,:]\n",
    "temp=np.load(\"/home/ziniuw/Tangdata/weight_64.npy\")\n",
    "temp = temp.reshape(64,1,9,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import mse_loss\n",
    "import sys\n",
    "sys.path.append(\"/home/ziniuw/Fixed_Kernel_CNN/models_8K\")\n",
    "from adam import Adam\n",
    "from utils import make_dataloader, load_var_noise, make_dataloader, print_param, rmse, fev, pcc, plot_responses_fit, \\\n",
    "    plot_spatial_mask, plot_stimuli\n",
    "from training_8K import train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_CNN(model, weight):\n",
    "    t = torch.from_numpy(weight)\n",
    "    t = t.type(torch.FloatTensor)\n",
    "    t = nn.Parameter(t.cuda())\n",
    "    model.first_layer.weight = t\n",
    "        \n",
    "    \n",
    "    #print(t.type())\n",
    "    #print(model.conv_module_list[0].weight.size())\n",
    "    return model\n",
    "def train_one(model, data, param, weight, first_layer_no_learn = False, show_every=1, return_model = False):\n",
    "    \n",
    "    tic = time.time()\n",
    "    batch_size = param['batch_size']\n",
    "    lr = param['lr']\n",
    "    l1 = param['l1']\n",
    "    l2 = param['l2']\n",
    "    max_epoch = param['max_epoch']\n",
    "    seed = param['seed']\n",
    "    \n",
    "    if seed != -1:\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    input_channel, input_size = data[0].shape[1], data[0].shape[2]\n",
    "    output_size = data[1].shape[0]\n",
    "    train_loader = make_dataloader(data[0], data[1], batch_size=batch_size, is_train=True)\n",
    "    valid_loader = make_dataloader(data[2], data[3], batch_size=batch_size, is_train=False)\n",
    "    test_loader = make_dataloader(data[4], data[5], batch_size=batch_size, is_train=False)\n",
    "    best_valCC = 0\n",
    "    best_model = None\n",
    "    \n",
    "    if first_layer_no_learn:\n",
    "        model = init_CNN(model, weight)\n",
    "        optimizer = Adam([{'params': model.conv.parameters()},\n",
    "                {'params': model.fc.parameters()}], \n",
    "                          lr=lr, l1=l1, weight_decay=l2, amsgrad=True)\n",
    "    else:\n",
    "        optimizer = Adam(model.parameters(), lr=lr, l1=l1, weight_decay=l2, amsgrad=True)\n",
    "    loss = []\n",
    "    val_corr = []\n",
    "    for epoch in range(max_epoch):\n",
    "        if (epoch + 1) % show_every == 0:\n",
    "            print(f\"Epoch {epoch + 1}:\")\n",
    "        loss.append(train(model, train_loader, optimizer))\n",
    "        valid_CC = test(model, valid_loader, 'Validation')[1]\n",
    "        valid_CC = sum(valid_CC)/len(valid_CC)\n",
    "        val_corr.append(valid_CC)\n",
    "        if (epoch + 1) % show_every == 0:\n",
    "            print(valid_CC)\n",
    "        if valid_CC > best_valCC:\n",
    "            #recover the best model by validation set\n",
    "            best_valCC = valid_CC\n",
    "            del best_model\n",
    "            best_model = copy.deepcopy(model)\n",
    "\n",
    "    print(\"Done Training\")\n",
    "    res = test(best_model, test_loader, 'Test')\n",
    "    test_corr = res[1]\n",
    "    pred = res[-1]\n",
    "    test_corr = sum(test_corr)/len(test_corr)\n",
    "    print(test_corr)\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Finished.\")\n",
    "    toc = time.time()\n",
    "    print(\"Elapsed time is {:.6f} seconds.\".format(toc - tic))\n",
    "    if return_model:\n",
    "        return best_model, test_corr, toc-tic, loss, pred\n",
    "    else:\n",
    "        return test_corr, toc-tic, loss, val_corr, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.noisify import noise_pred\n",
    "#fit one neuron at a time and document the performance, convergence and noise test\n",
    "model_arch = {'l1_c': 24, 'l1_k': 9, 'p1_k':3, 'p1_s':2, 'l2_c':16, 'l2_k':5, 'l2_s':1, 'p2_k':3, 'p2_s':2,\n",
    "             'l3_c':16, 'l3_k':5, 'l3_s':1, 'p3_k':3, 'p3_s':2}\n",
    "optm_param = {'batch_size': 64,'lr': 1e-4, 'l1': 1e-4, 'l2': 1e-5, 'max_epoch': 20, 'seed': 1}\n",
    "#set seed = -1 if you dont want to set seed.\n",
    "FK_corr = []\n",
    "FK_val_corr = []\n",
    "FK_noise = []\n",
    "for i in range(len(data_Sep)):\n",
    "    print(i)\n",
    "    model = FKCNN_3l(model_arch, input_size=128)\n",
    "    res = train_one(model.cuda(), data_Sep[i], optm_param, weight, show_every=10, first_layer_no_learn=True, return_model=True)\n",
    "    #best_model = res[0]\n",
    "    FK_corr.append(res[1])\n",
    "    #FK_val_corr.append(res[3])\n",
    "    #FK_noise.append(noise_pred(best_model, data_Sep[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arch = {'l1_c': 24, 'l1_k': 9, 'p1_k':3, 'p1_s':2, 'l2_c':16, 'l2_k':5, 'l2_s':1, 'p2_k':3, 'p2_s':2,\n",
    "             'l3_c':16, 'l3_k':5, 'l3_s':1, 'p3_k':3, 'p3_s':2}\n",
    "param = {'batch_size': 64,'lr': 1e-3, 'l1': 3e-5, 'l2': 1e-4, 'max_epoch': 30, 'seed': 1}\n",
    "#set seed = -1 if you dont want to set seed.\n",
    "CNN_corr = []\n",
    "CNN_val_corr = []\n",
    "CNN_noise = []\n",
    "for i in range(len(data_Sep)):\n",
    "    print(i)\n",
    "    model = FKCNN_3l(model_arch, input_size=128)\n",
    "    res = train_one(model.cuda(), data_Sep[i], param, None, show_every=10)\n",
    "    \n",
    "    CNN_corr.append(res[1])\n",
    "    best_model = res[0]\n",
    "    CNN_val_corr.append(res[3])\n",
    "    CNN_noise.append(noise_pred(best_model, data_Sep[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arch = {'l1_c': 24, 'l1_k': 9, 'p1_k':3, 'p1_s':2, 'l2_c':16, 'l2_k':5, 'l2_s':1, 'p2_k':3, 'p2_s':2,\n",
    "             'l3_c':16, 'l3_k':5, 'l3_s':1, 'p3_k':3, 'p3_s':2}\n",
    "optm_param = {'batch_size': 64,'lr': 1e-3, 'l1': 3e-5, 'l2': 1e-4, 'max_epoch': 30, 'seed': 1}\n",
    "#set seed = -1 if you dont want to set seed.\n",
    "G_corr = []\n",
    "G_val_corr = []\n",
    "G_noise = []\n",
    "for i in range(len(data_Sep)):\n",
    "    print(i)\n",
    "    model = FKCNN_3l(model_arch, input_size=128)\n",
    "    res = train_one(model.cuda(), data_Sep[i], optm_param, gabor, first_layer_no_learn = True)\n",
    "    G_corr.append(res[1])\n",
    "    best_model = res[0]\n",
    "    G_val_corr.append(res[3])\n",
    "    G_noise.append(noise_pred(best_model, data_Sep[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit all at the same time\n",
    "model_arch = {'l1_c': 24, 'l1_k': 9, 'p1_k':3, 'p1_s':2, 'l2_c':16, 'l2_k':5, 'l2_s':1, 'p2_k':3, 'p2_s':2,\n",
    "             'l3_c':16, 'l3_k':5, 'l3_s':1, 'p3_k':3, 'p3_s':2}\n",
    "param = {'batch_size': 64,'lr': 1e-3, 'l1': 3e-5, 'l2': 1e-4, 'max_epoch': 35, 'seed': 1}\n",
    "model = FKCNN_3l(model_arch, output_size=29)\n",
    "res = train_one(model.cuda(), data, param, None)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.plot_kernel import display_one_network\n",
    "kernel = model.first_layer.weight.data.cpu().numpy()\n",
    "display_one_network(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arch = {'l1_c': 24, 'l1_k': 9, 'p1_k':3, 'p1_s':2, 'l2_c':16, 'l2_k':5, 'l2_s':1, 'p2_k':3, 'p2_s':2,\n",
    "             'l3_c':16, 'l3_k':5, 'l3_s':1, 'p3_k':3, 'p3_s':2}\n",
    "optm_param = {'batch_size': 64,'lr': 1e-3, 'l1': 3e-5, 'l2': 1e-4, 'max_epoch': 30, 'seed': 1}\n",
    "G_pred = []\n",
    "FK_pred = []\n",
    "CNN_pred = []\n",
    "for i in range(len(data_Sep)):\n",
    "    print(i)\n",
    "    model = FKCNN_3l(model_arch, input_size=128)\n",
    "    G_pred.append(train_one(model.cuda(), data_Sep[i], optm_param, gabor, first_layer_no_learn = True)[-1])\n",
    "\n",
    "    model = FKCNN_3l(model_arch, input_size=128)\n",
    "    FK_pred.append(train_one(model.cuda(), data_Sep[i], optm_param, weight, first_layer_no_learn = True)[-1])\n",
    "\n",
    "    model = FKCNN_3l(model_arch, input_size=128)\n",
    "    CNN_pred.append(train_one(model.cuda(), data_Sep[i], optm_param, None)[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
