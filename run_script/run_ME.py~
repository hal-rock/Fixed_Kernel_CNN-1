import numpy as np
import h5py
import os
from collections import OrderedDict
import matplotlib.pyplot as plt
import time
from skimage import img_as_float
from torch import nn, FloatTensor
import torch
from torchvision.utils import make_grid
import sys
import copy
import importlib
sys.path.append('/home/ziniuw/Fixed_Kernel_CNN')
from util.get_data_pattern import prepare_dataset_pattern
from scipy.io import loadmat
from torch.nn.functional import mse_loss
import sys
from models_8K.adam import Adam
from models_8K.utils import make_dataloader, load_var_noise, make_dataloader, print_param, rmse, fev, pcc
from models_8K.training_8K import train, test
from models_Tang.model import FKCNN

def init_CNN(model, weight):
    t = torch.from_numpy(weight)
    t = t.type(torch.FloatTensor)
    t = nn.Parameter(t.cuda())
    model.first_layer.weight = t
        
    
    #print(t.type())
    #print(model.conv_module_list[0].weight.size())
    return model
def train_one(model, data, param, weight, first_layer_no_learn = False, show_every=1, return_model = False):
    
    tic = time.time()
    batch_size = param['batch_size']
    lr = param['lr']
    l1 = param['l1']
    l2 = param['l2']
    max_epoch = param['max_epoch']
    seed = param['seed']
    
    if seed != -1:
        torch.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    input_channel, input_size = data[0].shape[1], data[0].shape[2]
    output_size = data[1].shape[0]
    train_loader = make_dataloader(data[0], data[1], batch_size=batch_size, is_train=True)
    valid_loader = make_dataloader(data[2], data[3], batch_size=batch_size, is_train=False)
    test_loader = make_dataloader(data[4], data[5], batch_size=batch_size, is_train=False)
    best_valCC = 0
    best_model = None
    
    if first_layer_no_learn:
        model = init_CNN(model, weight)
        optimizer = Adam([{'params': model.conv.parameters()},
                {'params': model.fc.parameters()}], 
                          lr=lr, l1=l1, weight_decay=l2, amsgrad=True)
    else:
        optimizer = Adam(model.parameters(), lr=lr, l1=l1, weight_decay=l2, amsgrad=True)
    loss = []
    val_corr = []
    for epoch in range(max_epoch):
        if (epoch + 1) % show_every == 0:
            print(f"===> Training Epoch {epoch + 1}:")
        loss.append(train(model, train_loader, optimizer))
        valid_CC = test(model, valid_loader, 'Validation')[1]
        valid_CC = sum(valid_CC)/len(valid_CC)
        val_corr.append(valid_CC)
        if (epoch + 1) % show_every == 0:
            print(valid_CC)
        if valid_CC > best_valCC:
            best_valCC = valid_CC
            del best_model
            best_model = copy.deepcopy(model)

    print("===========>")
    res = test(best_model, test_loader, 'Test')
    test_corr = res[1]
    pred = res[-1]
    test_corr = sum(test_corr)/len(test_corr)
    print(test_corr)
    torch.cuda.empty_cache()
    print("Finished.")
    toc = time.time()
    print("Elapsed time is {:.6f} seconds.".format(toc - tic))
    if return_model:
        return best_model, test_corr, toc-tic, loss, val_corr, pred
    else:
        return test_corr, toc-tic, loss, val_corr, pred
    
    
def main():
    data = prepare_dataset_pattern('E') #load pattern data
    #load the pretrained weight, the index are pre-selected to reduce redundancy.
    weight = np.load("/home/ziniuw/Tangdata/filter_79.npy")
    weight = weight.reshape(79,1,9,9)
    weight = weight[[0,3,5,8,9,11,14,17,18,20,23,25,27,32,36,37,40,44,53,57,58,64,65,74],:,:,:]
    gabor = np.load("/home/ziniuw/Tangdata/gabor.npy")
    gabor = gabor.reshape(24,1,10,10)
    ref_data_mat = loadmat('/home/ziniuw/Tangdata/cell_classification_v3_ref.mat')
    OT_data_A = ref_data_mat['MkA_Lbl_OT'].ravel().astype(np.bool_)
    OT_A = np.array(np.where(OT_data_A == True)).ravel()
    HO_data_A = ref_data_mat['MkA_Lbl_HO'].ravel().astype(np.bool_)
    HO_A = np.array(np.where(HO_data_A == True)).ravel()
    FKCNN_optm_param = {'batch_size': 64,'lr': 3e-3, 'l1': 3e-5, 'l2': 1e-4, 'max_epoch': 200, 'seed': 1}
    CNN_optm_param = {'batch_size': 64,'lr': 1e-3, 'l1': 3e-5, 'l2': 1e-4, 'max_epoch': 200, 'seed': 1}
    n = len(data)
    neu_ind = np.zeros(n)
    res_corr = np.zeros((n, 4))
    val_corr = np.zeros((n, 4, 200))
    i = 0
    for neu in data:
        print(neu)
        neu_ind[i] = neu
        model = FKCNN(kernel_size=10, p1_k = 2)
        G_res = train_one(model.cuda(), data[neu], FKCNN_optm_param, gabor, first_layer_no_learn = True, show_every=500)
        res_corr[i,0] = G_res[0]
        val_corr[i,0,:] = G_res[3]
        
        
        model = FKCNN()
        FK_res = train_one(model.cuda(), data[neu], FKCNN_optm_param, weight, first_layer_no_learn = True, show_every=500)
        res_corr[i,1] = FK_res[0]
        val_corr[i,1,:] = FK_res[3]
        
        model = FKCNN(num_channel=4)
        CNN4_res = train_one(model.cuda(), data[neu], CNN_optm_param, None,show_every=500)
        res_corr[i,2] = CNN4_res[0]
        val_corr[i,2,:] = CNN4_res[3]

        model = FKCNN(num_channel=9)
        CNN9_res = train_one(model.cuda(), data[neu], CNN_optm_param, None,show_every=500)
        res_corr[i,3] = CNN9_res[0]
        val_corr[i,3,:] = CNN9_res[3]
        i+=1
        if (i+1)%100==0:
            np.save('neu_ind',neu_ind)
            np.save('test_corr',res_corr)
            np.save('val_corr', val_corr)
    np.save('neu_ind',neu_ind)
    np.save('test_corr',res_corr)
    np.save('val_corr', val_corr)
    
main()